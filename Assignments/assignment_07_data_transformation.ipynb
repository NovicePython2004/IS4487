{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NovicePython2004/IS4487/blob/main/Assignments/assignment_07_data_transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGEFsf2omI3"
      },
      "source": [
        "# IS 4487 Assignment 7: Data Transformation with Airbnb Listings\n",
        "\n",
        "In this assignment, you will:\n",
        "- Load the Airbnb dataset you cleaned in Assignment 6\n",
        "- Apply data transformation techniques like scaling, binning, encoding, and feature creation\n",
        "- Make the dataset easier to use for tasks like pricing analysis, guest segmentation, or listing recommendations\n",
        "- Practice writing up your analysis clearly so a business audience ‚Äî like a host, marketing manager, or city partner ‚Äî could understand it\n",
        "\n",
        "## Why This Matters\n",
        "\n",
        "Airbnb analysts, hosts, and city partners rely on clean and well-structured data to make smart decisions. Whether they‚Äôre adjusting prices, identifying high-performing listings, or designing better guest experiences, they need data that‚Äôs transformed, organized, and ready for use.\n",
        "\n",
        "This assignment helps you practice that kind of real-world thinking: taking messy real data and getting it ready for action.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Assignments/assignment_07_data_transformation.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpUh_f5Gny85"
      },
      "source": [
        "## Dataset Description\n",
        "\n",
        "The dataset you'll be using is a **detailed Airbnb listing file**, available from [Inside Airbnb](https://insideairbnb.com/get-the-data/).\n",
        "\n",
        "Each row represents one property listing. The columns include:\n",
        "\n",
        "- **Host attributes** (e.g., host ID, host name, host response time)\n",
        "- **Listing details** (e.g., price, room type, minimum nights, availability)\n",
        "- **Location data** (e.g., neighborhood, latitude/longitude)\n",
        "- **Property characteristics** (e.g., number of bedrooms, amenities, accommodates)\n",
        "- **Calendar/booking variables** (e.g., last review date, number of reviews)\n",
        "\n",
        "The schema is consistent across cities, so you can expect similar columns regardless of the location you choose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqwM6oP8nzJZ"
      },
      "source": [
        "## 1. Setup and Load Your Data\n",
        "\n",
        "You'll be working with the `cleaned_airbnb_data_6.csv` file you exported from Assignment 6. (Note: If you had significant errors with assignment 6, you can use the file named \"airbnb_listings.csv\" in the DataSets folder on GitHub as a backup starting point.)\n",
        "\n",
        "### Do the following:\n",
        "In Google Colab:\n",
        "- Click the folder icon on the left sidebar\n",
        "- Use the upload button to add your CSV file to the session\n",
        "- Then use the code block below to read it into your notebook\n",
        "\n",
        "Before getting started, make sure you import the libraries you'll need for this assignment:\n",
        "- `pandas`, `numpy` for data manipulation\n",
        "- `matplotlib.pyplot`, `seaborn` for visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN5pSvLRmvsW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_9LKnaqqowA"
      },
      "source": [
        "## 2. Check for Skew in a Numeric Column\n",
        "\n",
        "### Business framing:  \n",
        "\n",
        "Airbnb listings can have a wide range of values for things like price, availability, or reviews. These kinds of distributions can be hard to visualize, summarize, or model.\n",
        "\n",
        "### Do the following:\n",
        "Choose one **numeric column** that appears skewed and do the following:\n",
        "- Plot a histogram\n",
        "- Apply a transformation (e.g., log or other method)\n",
        "- Plot again to compare\n",
        "\n",
        "### In Your Response:\n",
        "1. What column did you examine?\n",
        "2. What transformation did you try, and why?\n",
        "3. How did the transformed version help make the data more usable for analysis or stakeholder review?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrnGKhtWqs-O"
      },
      "outputs": [],
      "source": [
        "column_to_transform = 'estimated_revenue_l365d'\n",
        "\n",
        "# Ensure the column exists and handle potential non-numeric types or missing values if they were not handled earlier\n",
        "if column_to_transform in df.columns:\n",
        "    # Filter out zero or negative values before log transformation\n",
        "    # Create a copy to avoid SettingWithCopyWarning\n",
        "    df_plot = df[df[column_to_transform] > 0].copy()\n",
        "\n",
        "    if not df_plot.empty:\n",
        "        # Plot histogram before transformation\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.histplot(df_plot[column_to_transform], kde=True)\n",
        "        plt.title(f'Original Distribution of {column_to_transform}')\n",
        "        plt.xlabel(column_to_transform)\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "        # Apply log transformation (using np.log1p for log(1+x) to handle values close to zero gracefully)\n",
        "        df_plot['log_transformed_revenue'] = np.log1p(df_plot[column_to_transform])\n",
        "\n",
        "        # Plot histogram after transformation\n",
        "        plt.subplot(1, 2, 2)\n",
        "        sns.histplot(df_plot['log_transformed_revenue'], kde=True)\n",
        "        plt.title(f'Log-Transformed Distribution of {column_to_transform}')\n",
        "        plt.xlabel(f'Log(1 + {column_to_transform})')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No positive values found in '{column_to_transform}' for plotting after filtering.\")\n",
        "else:\n",
        "    print(f\"Column '{column_to_transform}' not found in the DataFrame.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhlhDkPCqtlJ"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I examined the estimated_revenue_l365d column.\n",
        "\n",
        "2. I applied the log transofrmation in order to make the histogram easier to interpret visually.\n",
        "\n",
        "3. By transforming the data I am able to create visualizations that are easier to interpret by stakeholders thereby allowing them to make more informed business decisions. Addittionally many statistical models assume that data is normally distributed by making estimated_revenue_l365d more symmetrical we are able to increase the accuracy of these models while reducing the impact of extreme outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suJWVn_MsG8O"
      },
      "source": [
        "## 3. Scale Two Numeric Columns\n",
        "\n",
        "### Business framing:\n",
        "\n",
        "If an analyst wanted to compare listing price to number of nights required, or create a model that weighs both, those values need to be on a similar scale.\n",
        "\n",
        "### Do the following:\n",
        "- Pick two numeric columns with different value ranges (e.g. one column may have a min of 0 and a max of 255; another column may have a min of 100 and a max of 400)\n",
        "- Use Min-Max scaling on one column (the range should be ‚Äúshrinked‚Äù down to just 0-1)\n",
        "- Use Z-score Normalization (aka standardization) on the other column.\n",
        "- Add 2 new columns to the dataset. These 2 new columns should be the ones you just created.\n",
        "\n",
        "### In Your Response:\n",
        "1. What two columns did you scale, and which methods did you use?\n",
        "2. When might these scaled values be more useful than the originals?\n",
        "3. Who at Airbnb might benefit from this transformation and why?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Min-Max scale 'accommodates' column to 0-1 range\n",
        "min_max_scaler_accommodates = MinMaxScaler()\n",
        "df['accommodates_minmax_scaled'] = min_max_scaler_accommodates.fit_transform(df[['accommodates']])\n",
        "\n",
        "# Z-score normalize 'bedrooms' column\n",
        "standard_scaler_bedrooms = StandardScaler()\n",
        "df['bedrooms_zscore_scaled'] = standard_scaler_bedrooms.fit_transform(df[['bedrooms']])\n",
        "\n",
        "print(\"New columns 'accommodates_minmax_scaled' and 'bedrooms_zscore_scaled' created.\")\n",
        "print(df[['accommodates', 'accommodates_minmax_scaled', 'bedrooms', 'bedrooms_zscore_scaled']].head())\n"
      ],
      "metadata": {
        "id": "JHYm399HSj_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLcNZiFTshxf"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I scaled 'price' and 'accomodates'  into 'accomodates_minmax_scaled' and 'bedrooms' and 'availability_365' into 'bedrooms_zscore_scaled'. I used min-max and z-score to stanardize the infomation.\n",
        "2. Scaled models might becoe more useful when your using large language models as its easier for them to interpret and can prevent outliers and extreme values from skewing the result. Addittionally, z-score normalization helps to identify outliers by bringing data closer to a standard normal distribution, making extreme values stand out more. Furthermore transofrmations help to make data more interpretable.\n",
        "\n",
        "3. I believe that the owners of the properties can greatly benefit from this new infomation as well as investors that way they can more accurately chose where to invest in new properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmE4YNuXswVv"
      },
      "source": [
        "## 4. Group a Numeric Column into Categories\n",
        "\n",
        "### Business framing:  \n",
        "\n",
        "Let‚Äôs say an Airbnb marketing team wants to segment listings by review activity. They don‚Äôt want exact numbers ‚Äî they just want to know if a listing has ‚Äúlow,‚Äù ‚Äúmedium,‚Äù or ‚Äúhigh‚Äù review volume.\n",
        "\n",
        "### Do the following:\n",
        "\n",
        "- Choose a numeric column that could be grouped (e.g., reviews, availability).\n",
        "- You‚Äôll want to group the values of this column into 3 or 4 bins\n",
        "- Create a new column. The values of this column will be the labels: ‚ÄúLow‚Äù, ‚ÄúMedium‚Äù, and ‚ÄúHigh.‚Äù These labels should correspond to your bins.\n",
        "\n",
        "### In Your Response:\n",
        "1. What column did you group, and how many categories did you use?\n",
        "2. Why might someone prefer this grouped view over raw numbers?\n",
        "3. Who would this help at Airbnb, and how?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvuEmQS0s4mN"
      },
      "outputs": [],
      "source": [
        "column_to_group = 'number_of_reviews'\n",
        "\n",
        "# Define the number of bins and labels\n",
        "bins = 3\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "\n",
        "# Use pd.qcut to group the column into equal-sized bins (quantiles)\n",
        "# Handle potential errors if the column has too few unique values by using duplicates='drop'\n",
        "if df[column_to_group].nunique() < bins:\n",
        "    print(f\"Warning: Not enough unique values in '{column_to_group}' for {bins} bins. Using duplicates='drop'.\")\n",
        "    df['reviews_category'] = pd.qcut(df[column_to_group], q=bins, labels=labels, duplicates='drop')\n",
        "else:\n",
        "    df['reviews_category'] = pd.qcut(df[column_to_group], q=bins, labels=labels)\n",
        "\n",
        "# Display the value counts of the new categorical column\n",
        "print(\"Value counts for 'reviews_category':\")\n",
        "print(df['reviews_category'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_QWkf3vs6Td"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I grouped 'number_of_reviews' into 3 bins low, medium, and high.\n",
        "\n",
        "2. Someone might be prefer the bins over the individual data as it is easier to interpret adn it prevents extreme outliers from skewing the data.\n",
        "\n",
        "3. These bins help hosts who are not data minded by providing easy to interpret graphs that allows then to make imformed decisions with out the need for an indepth analysis. Aditionally this helps marketing managers to make tailored campaigns based on each bin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uvs7gFmvE1C"
      },
      "source": [
        "## 5. Create Two New Business-Relevant Variables\n",
        "\n",
        "### Business framing:  \n",
        "\n",
        "Stakeholders often want to know things like: What‚Äôs the cost per night? Are listings geared toward long-term stays? These kinds of features aren‚Äôt always in the dataset ‚Äî analysts create them.\n",
        "\n",
        "### Do the following:\n",
        "\n",
        "- Think of two new columns you can create using the data you already have.\n",
        "  - One might be a ratio or interaction between columns (e.g., price √∑ nights).\n",
        "  - The other might be a flag based on a condition (e.g., stays longer than 30 days).\n",
        "- Add the new columns to your DataFrame.\n",
        "\n",
        "### In Your Response:\n",
        "1. What two new columns did you create?\n",
        "2. Who would use them (e.g., host, manager, or platform)?\n",
        "3. How could they help someone make a better decision?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njqZvPNtvh7K"
      },
      "outputs": [],
      "source": [
        "# Create new column: price_per_rating\n",
        "# Handle potential division by zero or NaN in 'review_scores_rating'\n",
        "# Replace 0s with NaN to avoid ZeroDivisionError and propagate NaNs appropriately.\n",
        "df['price_per_rating'] = df['price'] / df['review_scores_rating'].replace(0, np.nan)\n",
        "\n",
        "# Create new column: price_per_person\n",
        "# Handle potential division by zero if 'accommodates' can be 0\n",
        "df['price_per_person'] = df['price'] / df['accommodates'].replace(0, np.nan)\n",
        "\n",
        "print(\"New columns 'price_per_rating' and 'price_per_person' created.\")\n",
        "print(df[['price', 'review_scores_rating', 'price_per_rating', 'accommodates', 'price_per_person']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BUYMsxYviaQ"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß üîß\n",
        "1. I created two columns: 'price_per_rating' and 'price_per_person'.\n",
        "\n",
        "2. I bleive hosts and managers will use them to see what is bringing in the most revneue and try to replicate that sucess to bring in more revenue.\n",
        "\n",
        "3. The 'price_per_rating' category helps identify if they are charging the appropitae price for the percved value. They can then make changes to increase the percieved value and then the price.\n",
        "\n",
        "The 'price_per_person' column assists in optimizing pricing for different group sizes as well as comparing their rates to their competitiors to make sure they are not over charging.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM-IqX-Qvvpn"
      },
      "source": [
        "## 6. Encode a Categorical Column\n",
        "\n",
        "### Business framing:  \n",
        "\n",
        "Let‚Äôs say you‚Äôre helping the Airbnb data science team build a model to predict booking rates. Categorical columns like `room_type`, `neighbourhood`, or `cancellation_policy` can‚Äôt be used in models unless they‚Äôre converted to numbers.\n",
        "\n",
        "### Do the following:\n",
        "- Choose one categorical column from your dataset (e.g., room type or neighborhood group)\n",
        "- Decide on an encoding method:\n",
        "  - Use one-hot encoding for nominal (unordered) categories\n",
        "  - Use ordinal encoding (a ranking) only if the categories have a clear order\n",
        "- Apply the encoding using `pandas` or another tool\n",
        "- Add the new encoded column(s) to your DataFrame\n",
        "\n",
        "### ‚úçÔ∏è In your markdown:\n",
        "1. What column did you encode and why?\n",
        "2. What encoding method did you use?\n",
        "3. How could this transformation help a pricing model, dashboard, or business report?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h4sCLvAIv-Xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a793852-e8d4-4dcd-8539-140063fdc1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoding applied to 'room_type'. New columns added to DataFrame.\n",
            "DataFrame head with new encoded columns:\n",
            "         room_type  room_type_Hotel room  room_type_Hotel room  \\\n",
            "0  Entire home/apt                 False                 False   \n",
            "1  Entire home/apt                 False                 False   \n",
            "2  Entire home/apt                 False                 False   \n",
            "3     Private room                 False                 False   \n",
            "4  Entire home/apt                 False                 False   \n",
            "\n",
            "   room_type_Private room  room_type_Private room  room_type_Shared room  \\\n",
            "0                   False                   False                  False   \n",
            "1                   False                   False                  False   \n",
            "2                   False                   False                  False   \n",
            "3                    True                    True                  False   \n",
            "4                   False                   False                  False   \n",
            "\n",
            "   room_type_Shared room  \n",
            "0                  False  \n",
            "1                  False  \n",
            "2                  False  \n",
            "3                  False  \n",
            "4                  False  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Choose the categorical column to encode\n",
        "column_to_encode = 'room_type'\n",
        "\n",
        "# Apply one-hot encoding using pd.get_dummies\n",
        "# drop_first=True is used to avoid multicollinearity in statistical models\n",
        "df_encoded = pd.get_dummies(df[column_to_encode], prefix=column_to_encode, drop_first=True)\n",
        "\n",
        "# Concatenate the new one-hot encoded columns to the original DataFrame\n",
        "df = pd.concat([df, df_encoded], axis=1)\n",
        "\n",
        "print(f\"One-hot encoding applied to '{column_to_encode}'. New columns added to DataFrame.\")\n",
        "print(\"DataFrame head with new encoded columns:\")\n",
        "print(df[[column_to_encode] + list(df_encoded.columns)].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpv-zfdOv_gE"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I encoded \"room_type\" becuase machine learning models and graphs usually require numeric imputs instead of categorical variables.\n",
        "2. I used hot encoding.\n",
        "3. By using hot encoding we are able to incorporate \"room_type\" as a feature. This allows models to be able to lear the specific price impact of each room. This in turn leads to more accurate pricing predictions and recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3koYU-yCGf48"
      },
      "source": [
        "## 7. Export Cleaned Data\n",
        "\n",
        "Before wrapping up, export your cleaned Airbnb dataset to a CSV file. You'll need this file for **Assignment 11**, where you'll use the data in a regression model.\n",
        "\n",
        "### Do the following:\n",
        "Make sure your data has:\n",
        "- Cleaned and consistent column values\n",
        "- Proper data types for each column\n",
        "- Any unnecessary columns removed\n",
        "\n",
        "This file should be the version of your dataset that you‚Äôd feel confident sharing with a teammate or using for deeper analysis.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Explanation:\n",
        "# - \"cleaned_airbnb_data_7.csv\" is the name of the file that will be saved\n",
        "# - index=False prevents pandas from writing row numbers into the CSV\n",
        "# - The file will be saved to your working directory (in Colab, you'll need to download it manually. Once you see the data in your files tab, just click on the three dots, then click ‚Äúdownload‚Äù)\n",
        "# - YOU MAY NEED TO PRESS ‚ÄúRUN‚Äù MULTIPLE TIMES IN ORDER FOR IT TO SHOW UP\n",
        "# - FOR SOME DEVICES, IT MAY TAKE A FEW MINUTES BEFORE YOUR FILE SHOWS UP\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eh8frvDGf48"
      },
      "outputs": [],
      "source": [
        "# export csv here üîß"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPm5yuDPwMSA"
      },
      "source": [
        "## 8. Reflection\n",
        "\n",
        "You‚Äôve applied the same kinds of transformation techniques used in real Airbnb analytics projects ‚Äî from pricing engines to host tools to tourism dashboards.\n",
        "\n",
        "Now step back and reflect.\n",
        "\n",
        "### In Your Response:\n",
        "1. What transformation step felt most important or interesting?\n",
        "2. Which of your changes would be most useful to a host, analyst, or city planner?\n",
        "3. If you were going to build a tool or dashboard, what would you do next with this data?\n",
        "4. How does this relate to your customized learning outcome you created in canvas?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OnJiBFcwTBn"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "3.\n",
        "4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBUTja5-Gf48"
      },
      "source": [
        "## Submission Instructions\n",
        "‚úÖ Checklist:\n",
        "- All code cells run without error\n",
        "- All markdown responses are complete\n",
        "- Submit on Canvas as instructed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6D5VzCpGf48",
        "outputId": "9bcca88b-b4bb-4aa5-d164-64a823f93f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern 'assignment_07_data_transformation.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbconvert --to html \"assignment_07_data_transformation.ipynb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6f45333"
      },
      "source": [
        "# Task\n",
        "Apply Min-Max scaling to the 'price' column, adding it as a new column named 'price_minmax_scaled', and Z-score normalization to the 'availability_365' column, adding it as 'availability_365_zscore_scaled', then verify the addition of these columns, and finally, answer the reflection questions in the markdown cell `TLcNZiFTshxf` about the scaled columns, methods used, their utility, and who at Airbnb would benefit from the transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d861ae8d"
      },
      "source": [
        "## Apply Min-Max Scaling to 'price'\n",
        "\n",
        "### Subtask:\n",
        "Scale the 'price' column to a range of 0-1 using MinMaxScaler and add it as a new column named 'price_minmax_scaled' to the DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b4662d7"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires scaling the 'price' column using Min-Max scaling. This involves instantiating the MinMaxScaler, applying it to the 'price' column with appropriate reshaping, and then adding the scaled values as a new column to the DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DcCZQtUvXgK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f555c343"
      },
      "source": [
        "## Apply Z-score Normalization to 'availability_365'\n",
        "\n",
        "### Subtask:\n",
        "Scale the 'availability_365' column using StandardScaler (Z-score normalization) and add it as a new column named 'availability_365_zscore_scaled' to the DataFrame.\n",
        "\n",
        "#### Instructions\n",
        "1. Instantiate a `StandardScaler` object.\n",
        "2. Apply Z-score normalization to the 'availability_365' column of the DataFrame `df` using the `.fit_transform()` method. Make sure to reshape the column using `.values.reshape(-1, 1)` before fitting.\n",
        "3. Assign the scaled values to a new column in `df` named 'availability_365_zscore_scaled'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34d37fd9"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the 'price' column has been Min-Max scaled, the next step according to the overall task is to apply Z-score normalization to the 'availability_365' column and add it as a new column to the DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "126797e0"
      },
      "source": [
        "standard_scaler = StandardScaler()\n",
        "df['availability_365_zscore_scaled'] = standard_scaler.fit_transform(df[['availability_365']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b43acc9b"
      },
      "source": [
        "**Reasoning**:\n",
        "To ensure the scaling operations were successful, it's important to verify the addition of the new scaled columns to the DataFrame and inspect their initial values. Displaying the head of the DataFrame will show these changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbd38982"
      },
      "source": [
        "print(df[['price', 'price_minmax_scaled', 'availability_365', 'availability_365_zscore_scaled']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ad9ef2f"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I scaled the 'price' column using Min-Max scaling, creating `price_minmax_scaled`. I scaled the 'availability_365' column using Z-score Normalization (StandardScaler), creating `availability_365_zscore_scaled`.\n",
        "\n",
        "2. These scaled values are more useful than the originals when comparing columns with vastly different ranges or when preparing data for machine learning models. For example, if we were building a model to predict booking rates, both price and availability would be important features. Without scaling, a model might disproportionately weigh 'price' due to its larger numerical range, even if 'availability_365' has a similar impact on the outcome. Scaling ensures that all features contribute equally to the model, preventing features with larger values from dominating.\n",
        "\n",
        "3. An Airbnb **analyst** would greatly benefit from these transformations. When comparing properties across different price points or availability schedules, scaled values allow for a more equitable comparison. For instance, comparing the 'value' of a high-priced listing with high availability versus a low-priced listing with low availability becomes more straightforward. Also, these scaled features are essential for building robust predictive models (e.g., for pricing recommendations or demand forecasting) as many algorithms perform better with scaled input data. A **marketing manager** could use these scaled values to segment listings or identify outliers more effectively, without being misled by raw numerical differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86edfe68"
      },
      "source": [
        "## Group a Numeric Column into Categories\n",
        "\n",
        "### Subtask:\n",
        "Group a numeric column (e.g., reviews, availability) into 3 or 4 categorical bins with labels like 'Low', 'Medium', and 'High', and add this as a new column to the DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aef557d"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires grouping a numeric column into categories. I will use 'number_of_reviews' as the chosen column, apply `pd.qcut` to create 3 bins, assign 'Low', 'Medium', 'High' labels, and store them in a new column named 'reviews_category'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d55e9204"
      },
      "source": [
        "# Choose a numeric column to group, for example, 'number_of_reviews'\n",
        "column_to_group = 'number_of_reviews'\n",
        "\n",
        "# Group the column into 3 bins using pd.qcut for equal-sized bins\n",
        "# Define the labels for the bins\n",
        "bins = 3\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "\n",
        "# Ensure the column has enough unique values for qcut to work with the specified number of bins\n",
        "# Handle potential errors if the column has too few unique values by using duplicates='drop'\n",
        "if df[column_to_group].nunique() < bins:\n",
        "    print(f\"Warning: Not enough unique values in '{column_to_group}' for {bins} bins. Adjusting bins or using cut instead.\")\n",
        "    # Fallback to cut if qcut fails due to too few unique values, or adjust bins\n",
        "    # For simplicity, if not enough unique values, we'll try to use fewer bins or handle as appropriate\n",
        "    # Here, I'll proceed with qcut and let it handle duplicates if they lead to fewer bins.\n",
        "    # Using duplicates='drop' to handle cases where there are many identical values.\n",
        "    df['reviews_category'] = pd.qcut(df[column_to_group], q=bins, labels=labels, duplicates='drop')\n",
        "else:\n",
        "    df['reviews_category'] = pd.qcut(df[column_to_group], q=bins, labels=labels)\n",
        "\n",
        "# Display the value counts of the new categorical column\n",
        "print(\"Value counts for 'reviews_category':\")\n",
        "print(df['reviews_category'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8133fd64"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I scaled the 'price' column using Min-Max scaling, creating `price_minmax_scaled`. I scaled the 'availability_365' column using Z-score Normalization (StandardScaler), creating `availability_365_zscore_scaled`.\n",
        "\n",
        "2. These scaled values are more useful than the originals when comparing columns with vastly different ranges or when preparing data for machine learning models. For example, if we were building a model to predict booking rates, both price and availability would be important features. Without scaling, a model might disproportionately weigh 'price' due to its larger numerical range, even if 'availability_365' has a similar impact on the outcome. Scaling ensures that all features contribute equally to the model, preventing features with larger values from dominating.\n",
        "\n",
        "3. An Airbnb **analyst** would greatly benefit from these transformations. When comparing properties across different price points or availability schedules, scaled values allow for a more equitable comparison. For instance, comparing the 'value' of a high-priced listing with high availability versus a low-priced listing with low availability becomes more straightforward. Also, these scaled features are essential for building robust predictive models (e.g., for pricing recommendations or demand forecasting) as many algorithms perform better with scaled input data. A **marketing manager** could use these scaled values to segment listings or identify outliers more effectively, without being misled by raw numerical differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dfee85f"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I grouped the 'number_of_reviews' column into three categories: 'Low', 'Medium', and 'High', using `pd.qcut` to ensure an approximately equal distribution of listings in each category.\n",
        "\n",
        "2. Someone might prefer this grouped view over raw numbers because it simplifies complex data into digestible segments. For a business audience, a simple classification like 'Low', 'Medium', or 'High' review volume is often more actionable and easier to understand than a precise numerical count. It helps in quickly identifying broad trends or segments without getting bogged down in individual data points.\n",
        "\n",
        "3. This would help an Airbnb **marketing manager** or **host success team**. A marketing manager could use these categories to tailor campaigns; for example, promoting 'High' review listings as premium options or targeting 'Low' review listings with advice on how to gather more reviews. The host success team could use this to identify hosts who might need assistance in improving their guest experience or encouraging more reviews, thereby improving the overall quality of listings on the platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "931897f6"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I grouped the 'number_of_reviews' column into three categories: 'Low', 'Medium', and 'High', using `pd.qcut` to ensure an approximately equal distribution of listings in each category.\n",
        "\n",
        "2. Someone might prefer this grouped view over raw numbers because it simplifies complex data into digestible segments. For a business audience, a simple classification like 'Low', 'Medium', or 'High' review volume is often more actionable and easier to understand than a precise numerical count. It helps in quickly identifying broad trends or segments without getting bogged down in individual data points.\n",
        "\n",
        "3. This would help an Airbnb **marketing manager** or **host success team**. A marketing manager could use these categories to tailor campaigns; for example, promoting 'High' review listings as premium options or targeting 'Low' review listings with advice on how to gather more reviews. The host success team could use this to identify hosts who might need assistance in improving their guest experience or encouraging more reviews, thereby improving the overall quality of listings on the platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5152fe31"
      },
      "source": [
        "### Subtask:\n",
        "- Create a new column named `price_per_person` by dividing the `price` column by the `accommodates` column.\n",
        "- Create a new binary flag column named `long_term_stay_flag` which is `1` if `minimum_nights` is greater than or equal to 30, and `0` otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8339081"
      },
      "source": [
        "### Subtask:\n",
        "- Create a new column named `price_per_person` by dividing the `price` column by the `accommodates` column.\n",
        "- Create a new binary flag column named `long_term_stay_flag` which is `1` if `minimum_nights` is greater than or equal to 30, and `0` otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "767edfe8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully provided the instructions for creating two new business-relevant variables. Now, I need to implement these instructions by adding the corresponding Python code to the specified code cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f49c3ec2"
      },
      "source": [
        "df['price_per_person'] = df['price'] / df['accommodates']\n",
        "df['long_term_stay_flag'] = (df['minimum_nights'] >= 30).astype(int)\n",
        "\n",
        "print(\"New columns 'price_per_person' and 'long_term_stay_flag' created.\")\n",
        "print(df[['price', 'accommodates', 'price_per_person', 'minimum_nights', 'long_term_stay_flag']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57b2a044"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I created two new columns:\n",
        "   - `price_per_person`: Calculated by dividing `price` by `accommodates`. This represents the cost of a stay per person per night.\n",
        "   - `long_term_stay_flag`: A binary flag (1 or 0) indicating whether the `minimum_nights` for a listing is 30 or more. This helps identify listings geared towards longer-term rentals.\n",
        "\n",
        "2. These columns would be used by:\n",
        "   - `price_per_person`: Primarily by **guests** looking for value, or by **analysts** for competitive pricing analysis. **Hosts** could also use it to benchmark their pricing strategy.\n",
        "   - `long_term_stay_flag`: Primarily by **analysts** for segmenting the market or by **marketing managers** to target specific campaigns (e.g., for digital nomads, temporary relocations). **City planners** might also use this to understand the availability of long-term housing options.\n",
        "\n",
        "3. They could help someone make a better decision by:\n",
        "   - `price_per_person`: For a **guest**, it simplifies comparing the cost-effectiveness of listings, especially when considering group bookings. For an **analyst**, it normalizes pricing across listings with different capacities, allowing for more accurate comparisons and identification of pricing opportunities or discrepancies. A **host** could use this to adjust their pricing to be more competitive on a per-person basis.\n",
        "   - `long_term_stay_flag`: For a **marketing manager**, this flag allows for targeted promotions to potential long-term renters, improving booking conversion for suitable listings. For **city planners**, it offers a quick way to assess the proportion of Airbnb listings that could potentially serve as longer-term housing, which is often a point of policy discussion. For **hosts**, it helps in understanding their market position (short-term vs. long-term) and tailoring their amenities and marketing accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc345509"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I created two new columns:\n",
        "   - `price_per_person`: Calculated by dividing `price` by `accommodates`. This represents the cost of a stay per person per night.\n",
        "   - `long_term_stay_flag`: A binary flag (1 or 0) indicating whether the `minimum_nights` for a listing is 30 or more. This helps identify listings geared towards longer-term rentals.\n",
        "\n",
        "2. These columns would be used by:\n",
        "   - `price_per_person`: Primarily by **guests** looking for value, or by **analysts** for competitive pricing analysis. **Hosts** could also use it to benchmark their pricing strategy.\n",
        "   - `long_term_stay_flag`: Primarily by **analysts** for segmenting the market or by **marketing managers** to target specific campaigns (e.g., for digital nomads, temporary relocations). **City planners** might also use this to understand the availability of long-term housing options.\n",
        "\n",
        "3. They could help someone make a better decision by:\n",
        "   - `price_per_person`: For a **guest**, it simplifies comparing the cost-effectiveness of listings, especially when considering group bookings. For an **analyst**, it normalizes pricing across listings with different capacities, allowing for more accurate comparisons and identification of pricing opportunities or discrepancies. A **host** could use this to adjust their pricing to be more competitive on a per-person basis.\n",
        "   - `long_term_stay_flag`: For a **marketing manager**, this flag allows for targeted promotions to potential long-term renters, improving booking conversion for suitable listings. For **city planners**, it offers a quick way to assess the proportion of Airbnb listings that could potentially serve as longer-term housing, which is often a point of policy discussion. For **hosts**, it helps in understanding their market position (short-term vs. long-term) and tailoring their amenities and marketing accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "138f7f28"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I created two new columns:\n",
        "   - `price_per_person`: Calculated by dividing `price` by `accommodates`. This represents the cost of a stay per person per night.\n",
        "   - `long_term_stay_flag`: A binary flag (1 or 0) indicating whether the `minimum_nights` for a listing is 30 or more. This helps identify listings geared towards longer-term rentals.\n",
        "\n",
        "2. These columns would be used by:\n",
        "   - `price_per_person`: Primarily by **guests** looking for value, or by **analysts** for competitive pricing analysis. **Hosts** could also use it to benchmark their pricing strategy.\n",
        "   - `long_term_stay_flag`: Primarily by **analysts** for segmenting the market or by **marketing managers** to target specific campaigns (e.g., for digital nomads, temporary relocations). **City planners** might also use this to understand the availability of long-term housing options.\n",
        "\n",
        "3. They could help someone make a better decision by:\n",
        "   - `price_per_person`: For a **guest**, it simplifies comparing the cost-effectiveness of listings, especially when considering group bookings. For an **analyst**, it normalizes pricing across listings with different capacities, allowing for more accurate comparisons and identification of pricing opportunities or discrepancies. A **host** could use this to adjust their pricing to be more competitive on a per-person basis.\n",
        "   - `long_term_stay_flag`: For a **marketing manager**, this flag allows for targeted promotions to potential long-term renters, improving booking conversion for suitable listings. For **city planners**, it offers a quick way to assess the proportion of Airbnb listings that could potentially serve as longer-term housing, which is often a point of policy discussion. For **hosts**, it helps in understanding their market position (short-term vs. long-term) and tailoring their amenities and marketing accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d37cff32"
      },
      "source": [
        "## 6. Encode a Categorical Column\n",
        "\n",
        "### Business framing:  \n",
        "\n",
        "Let‚Äôs say you‚Äôre helping the Airbnb data science team build a model to predict booking rates. Categorical columns like `room_type`, `neighbourhood`, or `cancellation_policy` can‚Äôt be used in models unless they‚Äôre converted to numbers.\n",
        "\n",
        "### Do the following:\n",
        "- Choose one categorical column from your dataset (e.g., room type or neighborhood group)\n",
        "- Decide on an encoding method:\n",
        "  - Use one-hot encoding for nominal (unordered) categories\n",
        "  - Use ordinal encoding (a ranking) only if the categories have a clear order\n",
        "- Apply the encoding using `pandas` or another tool\n",
        "- Add the new encoded column(s) to your DataFrame\n",
        "\n",
        "### ‚úçÔ∏è In your markdown:\n",
        "1. What column did you encode and why?\n",
        "2. What encoding method did you use?\n",
        "3. How could this transformation help a pricing model, dashboard, or business report?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28d116c9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step presented the instructions for encoding a categorical column. Now, I need to choose a suitable categorical column from the DataFrame, apply the appropriate encoding method, and add the resulting new columns to the DataFrame. 'room_type' is a nominal categorical column, making one-hot encoding a suitable choice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de7e486d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Choose a categorical column to encode, e.g., 'room_type'\n",
        "column_to_encode = 'room_type'\n",
        "\n",
        "# Apply one-hot encoding\n",
        "# drop_first=True helps avoid multicollinearity in models\n",
        "df_encoded = pd.get_dummies(df[column_to_encode], prefix=column_to_encode, drop_first=True)\n",
        "\n",
        "# Concatenate the new one-hot encoded columns to the original DataFrame\n",
        "df = pd.concat([df, df_encoded], axis=1)\n",
        "\n",
        "# Display the head of the DataFrame with the new columns and the value counts of the original column\n",
        "print(f\"Original '{column_to_encode}' value counts:\")\n",
        "print(df[column_to_encode].value_counts())\n",
        "print(\"\\nDataFrame head with new encoded columns:\")\n",
        "print(df[[column_to_encode] + list(df_encoded.columns)].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27a06e5e"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I encoded the 'room_type' column because it is a nominal categorical variable, meaning its categories (Entire home/apt, Private room, Hotel room, Shared room) have no intrinsic order. Machine learning models typically require numerical input, so converting this categorical data into a numerical format is essential for its use in such models.\n",
        "\n",
        "2. I used **One-Hot Encoding**. This method creates new binary columns for each category (except one, to avoid multicollinearity) where a '1' indicates the presence of that category and a '0' indicates its absence.\n",
        "\n",
        "3. This transformation can significantly help a **pricing model** by allowing it to factor in the impact of different room types on pricing. For example, 'Entire home/apt' listings typically command higher prices than 'Shared room' listings. Without encoding, the model wouldn't be able to process this information. In a **dashboard** or **business report**, these encoded features could be used to create visualizations or summaries that show the distribution of room types, or to analyze average prices/bookings per room type, providing clearer insights into market segments and their performance. For instance, an analyst could easily compare booking rates for 'Private room' vs. 'Entire home/apt' listings after this transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28388b19"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I encoded the 'room_type' column because it is a nominal categorical variable, meaning its categories (Entire home/apt, Private room, Hotel room, Shared room) have no intrinsic order. Machine learning models typically require numerical input, so converting this categorical data into a numerical format is essential for its use in such models.\n",
        "\n",
        "2. I used **One-Hot Encoding**. This method creates new binary columns for each category (except one, to avoid multicollinearity) where a '1' indicates the presence of that category and a '0' indicates its absence.\n",
        "\n",
        "3. This transformation can significantly help a **pricing model** by allowing it to factor in the impact of different room types on pricing. For example, 'Entire home/apt' listings typically command higher prices than 'Shared room' listings. Without encoding, the model wouldn't be able to process this information. In a **dashboard** or **business report**, these encoded features could be used to create visualizations or summaries that show the distribution of room types, or to analyze average prices/bookings per room type, providing clearer insights into market segments and their performance. For instance, an analyst could easily compare booking rates for 'Private room' vs. 'Entire home/apt' listings after this transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc08aa6f"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I encoded the 'room_type' column because it is a nominal categorical variable, meaning its categories (Entire home/apt, Private room, Hotel room, Shared room) have no intrinsic order. Machine learning models typically require numerical input, so converting this categorical data into a numerical format is essential for its use in such models.\n",
        "\n",
        "2. I used **One-Hot Encoding**. This method creates new binary columns for each category (except one, to avoid multicollinearity) where a '1' indicates the presence of that category and a '0' indicates its absence.\n",
        "\n",
        "3. This transformation can significantly help a **pricing model** by allowing it to factor in the impact of different room types on pricing. For example, 'Entire home/apt' listings typically command higher prices than 'Shared room' listings. Without encoding, the model wouldn't be able to process this information. In a **dashboard** or **business report**, these encoded features could be used to create visualizations or summaries that show the distribution of room types, or to analyze average prices/bookings per room type, providing clearer insights into market segments and their performance. For instance, an analyst could easily compare booking rates for 'Private room' vs. 'Entire home/apt' listings after this transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68fb1850"
      },
      "source": [
        "## 7. Export Cleaned Data\n",
        "\n",
        "Before wrapping up, export your cleaned Airbnb dataset to a CSV file. You'll need this file for **Assignment 11**, where you'll use the data in a regression model.\n",
        "\n",
        "### Do the following:\n",
        "Make sure your data has:\n",
        "- Cleaned and consistent column values\n",
        "- Proper data types for each column\n",
        "- Any unnecessary columns removed\n",
        "\n",
        "This file should be the version of your dataset that you‚Äôd feel confident sharing with a teammate or using for deeper analysis.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Explanation:\n",
        "# - \"cleaned_airbnb_data_7.csv\" is the name of the file that will be saved\n",
        "# - index=False prevents pandas from writing row numbers into the CSV\n",
        "# - The file will be saved to your working directory (in Colab, you'll need to download it manually. Once you see the data in your files tab, just click on the three dots, then click ‚Äúdownload‚Äù)\n",
        "# - YOU MAY NEED TO PRESS ‚ÄúRUN‚Äù MULTIPLE TIMES IN ORDER FOR IT TO SHOW UP\n",
        "# - FOR SOME DEVICES, IT MAY TAKE A FEW MINUTES BEFORE YOUR FILE SHOWS UP\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "216ba877"
      },
      "source": [
        "## Export Cleaned Data\n",
        "\n",
        "### Subtask:\n",
        "Export the cleaned Airbnb dataset to a CSV file named 'cleaned_airbnb_data_7.csv'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cad1e549"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to export the DataFrame `df` to a CSV file named 'cleaned_airbnb_data_7.csv' without the index. This requires using the `to_csv()` method with the specified filename and `index=False`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a306152e"
      },
      "source": [
        "df.to_csv('cleaned_airbnb_data_7.csv', index=False)\n",
        "print(\"DataFrame exported to 'cleaned_airbnb_data_7.csv'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7577168"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**1. What columns were scaled, what methods were used, and why are these scaled values more useful?**\n",
        "The 'price' column was scaled using Min-Max scaling, creating `price_minmax_scaled`, which normalizes values to a 0-1 range. The 'availability_365' column was scaled using Z-score normalization (StandardScaler), creating `availability_365_zscore_scaled`, which centers values around 0 with a standard deviation of 1. These scaled values are more useful for comparing columns with vastly different ranges or preparing data for machine learning models, as they ensure features contribute equally to models, preventing larger-valued features from dominating.\n",
        "\n",
        "**2. Who at Airbnb would benefit from the scaling transformations and how?**\n",
        "An Airbnb **analyst** would greatly benefit by enabling equitable comparisons of properties across different price points or availability, and for building robust predictive models. A **marketing manager** could use scaled values to segment listings or identify outliers more effectively, without being misled by raw numerical differences.\n",
        "\n",
        "**3. What column was grouped, how was it grouped, and why prefer this grouped view over raw numbers?**\n",
        "The 'number_of_reviews' column was grouped into three categories: 'Low', 'Medium', and 'High', using `pd.qcut` to ensure an approximately equal distribution of listings in each category. This grouped view simplifies complex data into digestible segments, making it more actionable and easier for business audiences to understand than precise numerical counts.\n",
        "\n",
        "**4. Who would benefit from the grouped view of reviews and how?**\n",
        "An Airbnb **marketing manager** could use these categories to tailor campaigns, promoting 'High' review listings or targeting 'Low' review listings with advice. The **host success team** could use this to identify hosts needing assistance in improving guest experience or encouraging more reviews.\n",
        "\n",
        "**5. What new columns were created, how were they calculated, and how do they help decision-making?**\n",
        "Two new columns were created:\n",
        "*   `price_per_person`: Calculated by dividing `price` by `accommodates`, representing the cost per person per night. This normalizes pricing for analysts, helps guests compare cost-effectiveness, and allows hosts to adjust competitive pricing.\n",
        "*   `long_term_stay_flag`: A binary flag (1 or 0) indicating if `minimum_nights` is greater than or equal to 30. This helps analysts segment the market for long-term rentals, enables marketing managers to target specific campaigns, and provides city planners insights into long-term housing options.\n",
        "\n",
        "**6. What categorical column was encoded, what method was used, and how could this transformation help a pricing model, dashboard, or business report?**\n",
        "The 'room_type' column was encoded using **One-Hot Encoding** because it is a nominal categorical variable with no intrinsic order. This transformation allows a **pricing model** to factor in the impact of different room types on pricing. For a **dashboard** or **business report**, these encoded features facilitate visualizations and summaries to analyze the distribution of room types or average prices/bookings per room type, providing clearer insights into market segments.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The 'price' column was successfully Min-Max scaled to a range of 0-1 and stored in `price_minmax_scaled`.\n",
        "*   The 'availability_365' column was successfully Z-score normalized (StandardScaler) and stored in `availability_365_zscore_scaled`.\n",
        "*   The 'number_of_reviews' column was grouped into 'Low', 'Medium', and 'High' categories using `pd.qcut`, resulting in a distribution of 10234 'Low' reviews, 9133 'High' reviews, and 8215 'Medium' reviews.\n",
        "*   Two new business-relevant columns were created: 'price_per_person' (calculated as `price / accommodates`) and 'long_term_stay_flag' (binary flag for `minimum_nights` >= 30).\n",
        "*   The 'room_type' column was successfully one-hot encoded, generating new binary columns such as `room_type_Hotel room`, `room_type_Private room`, and `room_type_Shared room`.\n",
        "*   The fully transformed and prepared DataFrame was exported to a CSV file named 'cleaned_airbnb_data_7.csv'.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The created scaled and engineered features are crucial for building robust machine learning models (e.g., pricing prediction, demand forecasting) by ensuring feature parity and providing direct business insights.\n",
        "*   The transformed dataset, complete with new categorical groupings and binary flags, offers enhanced analytical capabilities for various Airbnb stakeholders, enabling more targeted marketing, host support strategies, and market segmentation analyses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edf06ebd"
      },
      "source": [
        "# Task\n",
        "Normalize the new business-relevant columns 'price_per_rating' and 'price_per_person' using Z-score normalization (StandardScaler), adding them as new columns named 'price_per_rating_zscore_scaled' and 'price_per_person_zscore_scaled' respectively to the DataFrame, and then display the head of the DataFrame to verify these additions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca05aa9a"
      },
      "source": [
        "## Normalize 'price_per_rating'\n",
        "\n",
        "### Subtask:\n",
        "Apply Z-score normalization to the 'price_per_rating' column using StandardScaler and add it as a new column named 'price_per_rating_zscore_scaled' to the DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da82e2f6"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires applying Z-score normalization to the 'price_per_rating' column and adding it as a new column. Before scaling, it's important to handle any `NaN` values, which were introduced when `review_scores_rating` was zero. Imputing these NaNs with the median of 'price_per_rating' is a robust approach before applying `StandardScaler`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92978f2a"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Impute NaN values in 'price_per_rating' with its median before scaling\n",
        "# Create a temporary column or copy for imputation to not alter the original 'price_per_rating' if needed elsewhere raw\n",
        "price_per_rating_imputed = df['price_per_rating'].fillna(df['price_per_rating'].median())\n",
        "\n",
        "# Instantiate StandardScaler\n",
        "standard_scaler_price_per_rating = StandardScaler()\n",
        "\n",
        "# Apply Z-score normalization and create the new column\n",
        "df['price_per_rating_zscore_scaled'] = standard_scaler_price_per_rating.fit_transform(price_per_rating_imputed.values.reshape(-1, 1))\n",
        "\n",
        "print(\"New column 'price_per_rating_zscore_scaled' created.\")\n",
        "print(df[['price_per_rating', 'price_per_rating_zscore_scaled']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "041f5ff5"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that 'price_per_rating' has been normalized, the next step is to apply Z-score normalization to the 'price_per_person' column and add it to the DataFrame. I will impute any NaN values in 'price_per_person' with its median before scaling, similar to the previous step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acea1afa"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Impute NaN values in 'price_per_person' with its median before scaling\n",
        "price_per_person_imputed = df['price_per_person'].fillna(df['price_per_person'].median())\n",
        "\n",
        "# Instantiate StandardScaler for 'price_per_person'\n",
        "standard_scaler_price_per_person = StandardScaler()\n",
        "\n",
        "# Apply Z-score normalization and create the new column\n",
        "df['price_per_person_zscore_scaled'] = standard_scaler_price_per_person.fit_transform(price_per_person_imputed.values.reshape(-1, 1))\n",
        "\n",
        "print(\"New column 'price_per_person_zscore_scaled' created.\")\n",
        "print(df[['price_per_person', 'price_per_person_zscore_scaled']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1d38cdf"
      },
      "source": [
        "**Reasoning**:\n",
        "Both 'price_per_rating' and 'price_per_person' have been normalized. Now, I need to display the head of the DataFrame to verify the addition and correct scaling of both 'price_per_rating_zscore_scaled' and 'price_per_person_zscore_scaled' columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bed7f1b"
      },
      "source": [
        "print(df[['price_per_rating', 'price_per_rating_zscore_scaled', 'price_per_person', 'price_per_person_zscore_scaled']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ca1174"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I created two new columns:\n",
        "   - `price_per_rating_zscore_scaled`: This is the Z-score normalized value of the `price_per_rating` column. `price_per_rating` was originally calculated by dividing `price` by `review_scores_rating`.\n",
        "   - `price_per_person_zscore_scaled`: This is the Z-score normalized value of the `price_per_person` column. `price_per_person` was originally calculated by dividing `price` by `accommodates`.\n",
        "\n",
        "2. These normalized columns would be used by:\n",
        "   - `price_per_rating_zscore_scaled`: Primarily by **analysts** or **data scientists** building machine learning models for pricing optimization or listing recommendations. It helps compare listings' price-to-quality ratio on a standardized scale.\n",
        "   - `price_per_person_zscore_scaled`: Also primarily by **analysts** or **data scientists** for modeling, especially when segmenting listings by value or predicting booking rates. It allows for fair comparison of value for money across listings of different capacities.\n",
        "\n",
        "3. They could help someone make a better decision by:\n",
        "   - `price_per_rating_zscore_scaled`: For an **analyst**, this scaled feature makes it easier to identify listings that are either exceptionally good value (low price relative to high rating) or potentially overpriced (high price relative to low rating) without the bias of large absolute price values. This can inform host recommendations for pricing adjustments or platform-wide marketing strategies.\n",
        "   - `price_per_person_zscore_scaled`: For a **data scientist**, using this normalized feature in a predictive model ensures that the model treats 'price per person' fairly, regardless of its original numerical range, preventing features with larger numerical values from dominating the model's learning process. This leads to more accurate models for things like demand forecasting or personalized recommendations, which can inform strategic decisions for **marketing managers** and **business development teams**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f57767f"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. I created two new columns:\n",
        "   - `price_per_rating_zscore_scaled`: This is the Z-score normalized value of the `price_per_rating` column. `price_per_rating` was originally calculated by dividing `price` by `review_scores_rating`.\n",
        "   - `price_per_person_zscore_scaled`: This is the Z-score normalized value of the `price_per_person` column. `price_per_person` was originally calculated by dividing `price` by `accommodates`.\n",
        "\n",
        "2. These normalized columns would be used by:\n",
        "   - `price_per_rating_zscore_scaled`: Primarily by **analysts** or **data scientists** building machine learning models for pricing optimization or listing recommendations. It helps compare listings' price-to-quality ratio on a standardized scale.\n",
        "   - `price_per_person_zscore_scaled`: Also primarily by **analysts** or **data scientists** for modeling, especially when segmenting listings by value or predicting booking rates. It allows for fair comparison of value for money across listings of different capacities.\n",
        "\n",
        "3. They could help someone make a better decision by:\n",
        "   - `price_per_rating_zscore_scaled`: For an **analyst**, this scaled feature makes it easier to identify listings that are either exceptionally good value (low price relative to high rating) or potentially overpriced (high price relative to low rating) without the bias of large absolute price values. This can inform host recommendations for pricing adjustments or platform-wide marketing strategies.\n",
        "   - `price_per_person_zscore_scaled`: For a **data scientist**, using this normalized feature in a predictive model ensures that the model treats 'price per person' fairly, regardless of its original numerical range, preventing features with larger numerical values from dominating the model's learning process. This leads to more accurate models for things like demand forecasting or personalized recommendations, which can inform strategic decisions for **marketing managers** and **business development teams**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91db8921"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Conclude the normalization of the new business-relevant columns by providing a written reflection on the scaled columns, methods used, their utility, and who at Airbnb would benefit from the transformation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13e3bb73"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **What columns were created and what methods were used for their normalization?**\n",
        "    Two new columns were created: `price_per_rating_zscore_scaled` and `price_per_person_zscore_scaled`. Both were normalized using Z-score normalization (StandardScaler). Prior to scaling, any missing (NaN) values in the original `price_per_rating` and `price_per_person` columns were imputed with their respective medians.\n",
        "2.  **What is the utility of these scaled columns?**\n",
        "    The `price_per_rating_zscore_scaled` column standardizes the price-to-quality ratio, allowing for unbiased comparison of listings regardless of their absolute price. The `price_per_person_zscore_scaled` column standardizes the value for money across listings of varying capacities, ensuring fair comparison.\n",
        "3.  **Who at Airbnb would benefit from this transformation and how?**\n",
        "    *   **Analysts and Data Scientists** would benefit significantly by using these normalized features in machine learning models for pricing optimization, listing recommendations, demand forecasting, and predicting booking rates. Normalization prevents features with larger numerical ranges from dominating model learning.\n",
        "    *   This can inform **host recommendations** for pricing adjustments and influence **platform-wide marketing strategies**.\n",
        "    *   **Marketing Managers and Business Development Teams** can leverage insights from more accurate models (enabled by these scaled features) to make better strategic decisions, such as segmenting listings by value or improving personalized recommendations.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Two new columns, `price_per_rating_zscore_scaled` and `price_per_person_zscore_scaled`, were successfully added to the DataFrame, containing the Z-score normalized values of their respective original columns.\n",
        "*   Before applying Z-score normalization using `StandardScaler`, NaN values in both the `price_per_rating` and `price_per_person` columns were imputed with their medians to ensure robust scaling.\n",
        "*   The `head()` of the DataFrame confirms the successful creation and population of these scaled columns alongside their original counterparts.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The Z-score normalized columns provide a standardized basis for comparing diverse listings, which is critical for building unbiased and robust machine learning models for pricing, recommendations, and demand forecasting.\n",
        "*   These scaled features enable Airbnb to better identify outliers or exceptional value listings, facilitating targeted strategic interventions for hosts, guests, and overall platform optimization.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}